This project involves creating an eye gesture control system using Python, OpenCV, PyAutoGUI, and Mediapipe. The main goal of the project is to allow users to control the 
mouse cursor on their computer by tracking their eye movements through a webcam.

**Libraries Used:**

OpenCV (cv2): Used for capturing video frames from the webcam and image processing.
PyAutoGUI: Used for controlling the mouse cursor.
Mediapipe: Used for facial and hand landmark detection, specifically for tracking eye movements.

The eye gesture control project has potential use cases in various scenarios, providing an alternative input method for users who may have difficulty using traditional input devices. Here are some potential use cases for this project:
**Accessibility:**
Assistive Technology: Individuals with physical disabilities or limited mobility can use this system as an assistive technology to control the mouse cursor, providing them with greater independence.
Hands-Free Operation:

Hands-Free Computing: In situations where users cannot use their hands, such as cooking, laboratory work, or medical procedures, this system allows for hands-free computer interaction.
Presentations and Demonstrations:

Presenter Control: Presenters and speakers can use eye gestures to control presentations or demonstrations without the need for a physical clicker or keyboard.
Gaming:

Gaming Interaction: Gamers with specific requirements or those looking for innovative input methods can use eye gestures for controlling in-game actions or navigating menus.
